\subsection{Autocorrelation function}
\label{subsec:analysis-characterisation-acf}

This report explores the cross-correlation and autocorrelation functions, adapted to a population of noisy time series, as a method to characterise the periodicity and heterogeneity of oscillatory time series.  The report does so through simulated oscillatory time series based on models with very well-characterised behaviours: a harmonic oscillator and a relaxation oscillator.  The hope is that these synthetic time series can adequately model flavin fluorescence oscillations and the behaviour of histones during the cell division cycle.

\subsubsection{Mathematical basis}
\label{subsubsec:analysis-correlation-maths}
% \subsubsection{Simulating oscillators}
% \label{sec:analysis-correlation-maths-osc}

I choose the harmonic oscillator and the FitzHugh-Nagumo model to investigate because they are simple, well-characterised, and mimic the biological time series that I am interested in.  Here I detail the rationale behind my choices and describe the oscillators I choose.

\begin{enumerate}
\item Harmonic oscillator
\label{sec:org7f23d98}

I choose the harmonic oscillator because it is the simplest case of an oscillator, with only one parameter.  Namely:

\(\frac{d^{2}y}{dt^{2}} = -\omega^{2}y\)

where \(y\) represents displacement and \(\omega\) represents the angular frequency.

Or written in the form of a system of first-order differential equations:

\(\frac{dy}{dt} = v\)

\(\frac{dv}{dt} = -\omega^{2}y\)

This model produces time series \(y(t)\) that is a sinusoid, i.e.

\(y(t) = A sin(\omega{}t + \phi)\)

where \(A\) and \(\phi\) are determined by initial conditions.

\item FitzHugh-Nagumo model
\label{sec:orgdffb616}

I choose the FitzHugh-Nagumo model because it is a well-characterised relaxation oscillator that can model a more complicated time series, while still being simple, with only four parameters.

The FitzHugh-Nagumo model was developed to model an excitable system, such as a neuron.  The model is described as a system of first-order differential equations (citation needed):

\(\frac{dv}{dt} = v - \frac{v^3}{3} - w + RI_{\mathrm{ext}}\)

\(\tau \frac{dw}{dt} = v + a - bw\)

where the variables include:
\begin{description}
\item[{\(v\)}] membrane voltage
\item[{\(w\)}] linear recovery variable
\end{description}

and the parameters include \(RI_{\mathrm{ext}}\) (external stimulus), \(\tau\), \(a\), and \(b\) [describe what they are and how they control the model].

This model produces time series \(v(t)\) that is a relaxation oscillator [why relaxation oscillator?].
\end{enumerate}

% \subsubsection{Generating noise}
% \label{sec:analysis-correlation-maths-noise}

Biological time series, and certainly the ones that I study, have noise.  So, it makes sense to add noise to our models as well, because noise affects the behaviour of models and the analysis methods applied to the time series generated by our models.

Here, I describe two types of noise I investigate and how to integrate them with my models.

\begin{enumerate}
\item Gaussian noise
\label{sec:org38e563f}

[To clarify: should I use white noise or Gaussian noise?  These are not equivalent, but can overlap.  Current code generates Gaussian noise.]

I use (white) Gaussian noise as it is the simplest, first-approach case.  This noise is generated by randomly drawing samples from the normal distribution \(\mathcal{N}(1,0)\).

[Figure may be useful, but only to contrast with Gillespie noise.]

\item Gillespie noise from birth-death process
\label{sec:orge5d486b}

I use Gillespie noise because it's the same type of noise from biological systems [citation needed, maybe Wilkinson `Stochastic Modelling for Systems Biology'].

The Gillespie noise was generated as follows, using example parameter values:

Define the birth-death process: birth rate \(k_{0} = 5\) and death rate \(d_{0} = 0.05\).  Set a stochastic simulation with final time of 1500, and put the trajectories on a grid with regularly-spaced time points, 1000 time points in this case.

Each trajectory took some time to reach steady state (see image below), so the latter half was taken, assuming it is in steady-state:
\begin{center}
\includegraphics[width=.9\linewidth]{gillespie.png}
\end{center}

Here, the steady-state mean is equal to the steady-state variance, which is equal to \(k_{0}/d_{0}\).

I normalised this trajectory by subtracting the mean (\(k_{0}/d_{0}\)) and then dividing by \(\sqrt{1/d_{0}}\) to create Gillespie noise with mean 0 and standard deviation \(\sqrt{k_{0}}\) -- this is so that changes in \(k_{0}\) affect the noise amplitude.

As an example, I show 3 trajectories of Gillespie noise using the initial parameters I set:
\begin{center}
\includegraphics[width=.9\linewidth]{gillespie_noise_samples.png}
\end{center}

Alternatively, Gillespie noise can be parametrised in the form of standard deviation of noise amplitude \(A = \sqrt{k_{0}/d_{0}}\) and noise timescale \(\tau = 1/d_{0}\).

\item Adding noise
\label{sec:org03ea61a}

Approach: add to time series (simple sum).
\end{enumerate}

\subsubsection{Computing autocorrelation and cross-correlation}
\label{sec:analysis-correlation-maths-algorithm}

TODO: Describe the algorithm using mathematical notation (copy from BABY paper).  Mention that autocorrelation is a special case of cross-correlation.

TODO: Justify deviations from the `classical' mathematical definition, e.g. how a population of signals is treated, subtracting mean, etc. (This will be obvious when I write down the `classical' definition).  Also talk about: stationary option (mean across replicates and time points).

\subsection{Results}
\label{sec:analysis-correlation-results}

\begin{enumerate}
\item Autocorrelation on sinusoids
\label{sec:org2fe8e39}

\begin{enumerate}
\item Without noise: signals must be out of phase
\label{sec:orgeef3284}

Need to make sure that we understand the autocorrelation function, so we start from the simplest case: the sinusoid.  Want to understand what processes control the shape of autocorrelation and cross correlation functions.

In-phase sinusoids to be used as input data:
\begin{center}
\includegraphics[width=.9\linewidth]{sinusoids_inphase.png}
\end{center}

Autocorrelation functions of in-phase sinusoids are identical and only show noise, therefore uninformative:
\begin{center}
\includegraphics[width=.9\linewidth]{sinusoids_inphase_acf.png}
\end{center}

As the underlying dynamic process is stationary with a constant mean, we can modify our calculation of the autocorrelation function so that the mean is calculated over time and replicates.  This modification allows us to deal with in-phase sinusoids, with this results confirming this:
\begin{center}
\includegraphics[width=.9\linewidth]{sinusoids_inphase_acf_stationary.png}
\end{center}

A different set of input data is then generated with a random initial phase sampled from the distribution \(Unif[0,2\pi)\).
\begin{center}
\includegraphics[width=.9\linewidth]{sinusoids_outofphase.png}
\end{center}

Autocorrelation functions of out-of-phase sinusoids resemble a cosine wave with an amplitude of 1, which is how they should be in theory.
As a check, each oscillation of the autocorrelation function corresponds to the period of the source oscillations:
\begin{center}
\includegraphics[width=.9\linewidth]{sinusoids_outofphase_acf_corrected.png}
\end{center}

\item Mixed frequencies
\label{sec:orgbc4bd46}

As additional investigation on a population with mixed frequencies: 200 sinusoids of frequency 0.03 and 20 sinusoids of frequency 0.04

Autocorrelation function, lag axis scaled by frequency 0.03:
\begin{center}
\includegraphics[width=.9\linewidth]{sinusoids_mixed_acf_freq0p03.png}
\end{center}

Autocorrelation function, lag axis scaled by frequency 0.04:
\begin{center}
\includegraphics[width=.9\linewidth]{sinusoids_mixed_acf_freq0p04.png}
\end{center}

\item With Gaussian noise
\label{sec:org07e90f1}

In-phase sinusoids with Gaussian noise (standard deviation 0.3), to be used as input data:
\begin{center}
\includegraphics[width=.9\linewidth]{noisysinusoids_inphase.png}
\end{center}

The variation between autocorrelation functions of each in-phase sinusoids is only due to the Gaussian noise added, and therefore uninformative:
\begin{center}
\includegraphics[width=.9\linewidth]{noisysinusoids_inphase_acf.png}
\end{center}

Again, we can used the modified calculation because the underlying dynamic process is stationary with a constant mean.  In this case, the results are similar to as before (without Gaussian noise).
\begin{center}
\includegraphics[width=.9\linewidth]{noisysinusoids_inphase_acf_stationary.png}
\end{center}

We repeat the investigation but with a random initial phase:
\begin{center}
\includegraphics[width=.9\linewidth]{noisysinusoids_outofphase.png}
\end{center}

Autocorrelation functions of out-of-phase noisy sinusoids resemble a cosine wave with an amplitude of 1, which is how they should be in theory:
\begin{center}
\includegraphics[width=.9\linewidth]{noisysinusoids_outofphase_acf.png}
\end{center}

To emphasise the effect of noise, here I repeat the analysis with noise standard deviation 3.0:
\begin{center}
\includegraphics[width=.9\linewidth]{verynoisysinusoids_outofphase_acf.png}
\end{center}

Here, the amplitude of the autocorrelation functions are decreased and the variation between each time series' autocorrelation function is increased.  And at higher lag times, this variation is greater because there is less data that is used.  This is exemplified in this plot:
\begin{center}
\includegraphics[width=.9\linewidth]{lag_datapoints_vs_stddevacf.png}
\end{center}

  \item With Gillespie noise
\label{sec:org30f0d40}

\begin{enumerate}
\item Approach
\label{sec:orgd554193}

Create an oscillator.  Simulate Gillespie noise using a birth-death process, then add to oscillator.

Vary timescale and amplitude of noise with respect to signal.

\item Constructing replicates
\label{sec:orge2355a3}

I performed 100 replicates of a sinusoid of frequency 0.03 with different phases.  I then generated 100 trajectories to Gillespie noise as described above, and added them together to produce the simulated replicates.  This gave the following mean across replicates and autocorrelation function:
\begin{center}
\includegraphics[width=.9\linewidth]{gillespie_k5_d0p05_mean.png}
\end{center}
\begin{center}
\includegraphics[width=.9\linewidth]{gillespie_k5_d0p05_acf.png}
\end{center}

As a check, I drew an exponential decay function (\(y = e^{-2d_{0}T}\), where \(T\) represents lag) to the autocorrelation function.  The exponential function should fit the median autocorrelation function.

In addition, the oscillations in the autocorrelation function should occur every period of the sinusoid, as already shown above.

\item Varying timescale of noise
\label{sec:org7d5f612}

Changing the death rate \(d_{0}\) to 0.5 -- higher death rate seems to decrease the decay timescale for the autocorrelation function:
\begin{center}
\includegraphics[width=.9\linewidth]{gillespie_k5_d0p5_mean.png}
\end{center}
\begin{center}
\includegraphics[width=.9\linewidth]{gillespie_k5_d0p5_acf.png}
\end{center}

Changing the death rate \(d_{0}\) to 0.005.  Lower death rate seems to introduce long-term trends in the simulated signals.  It also increase the decay timescale for the autocorrelation function and increases the variation between autocorrelation functions between replicates.
\begin{center}
\includegraphics[width=.9\linewidth]{gillespie_k5_d0p005_mean.png}
\end{center}
\begin{center}
\includegraphics[width=.9\linewidth]{gillespie_k5_d0p005_acf.png}
\end{center}

I then fit exponential decay functions of the form \(y = (1-C)e^{-kT}+C\), using non-linear least squares, to the mean autocorrelation function, the peaks of this mean function, and the troughs of these functions.  As an example:
\begin{center}
\includegraphics[width=.9\linewidth]{acf_fit_example.png}
\end{center}

In theory, the decay rate \(k\) should scale linearly with the death rate \(d_{0}\).  Sweeping across values of \(d_{0}\), I confirm that is the case.  This figure thus summarises the effect of death rate in decay timescale:
\begin{center}
\includegraphics[width=.9\linewidth]{deathrate_vs_decay.png}
\end{center}

To quantify the variation between autocorrelation functions between replicates, I computed the standard deviation autocorrelation function values at each lag:
\begin{center}
\includegraphics[width=.9\linewidth]{stddevauc_example.png}
\end{center}

and then computed the area under this curve as a proxy for the variation between replicates.

As the noise timescale \(1/d_{0}\) increased, this area under curve increased:
\begin{center}
\includegraphics[width=.9\linewidth]{deathrate_vs_auc.png}
\end{center}

\item Varying amplitude of noise
\label{sec:org4110edb}

Changing the birth rate \(k_{0}\) to 1.  Lower birth rate decreases the amplitude of noise.  It also makes the autocorrelation function more robust and decreases the variation between replicates.
\begin{center}
\includegraphics[width=.9\linewidth]{gillespie_k1_d0p05_mean.png}
\end{center}
\begin{center}
\includegraphics[width=.9\linewidth]{gillespie_k1_d0p05_acf.png}
\end{center}

Changing the birth rate \(k_{0}\) to 25.  Higher birth rate increases the amplitude of noise.   It also makes the autocorrelation function less robust and increases the variation between replicates.
\begin{center}
\includegraphics[width=.9\linewidth]{gillespie_k25_d0p05_mean.png}
\end{center}
\begin{center}
\includegraphics[width=.9\linewidth]{gillespie_k25_d0p05_acf.png}
\end{center}

Similar to previously, I fit \(y = (1-C)e^{-kT}+C\), using non-linear least squares, to the mean autocorrelation function, the peaks of this mean function, and the troughs of these functions.

To show that the amplitude of the oscillations in the autocorrelation function decreases as the birth rate increases, I plotted the fitted \(C\) (y-displacement) parameters against the noise amplitude \(k_{0}/d_{0}\):
\begin{center}
\includegraphics[width=.9\linewidth]{birthrate_vs_ydispl.png}
\end{center}

Additionally, I subtracted the decay equation fitted to the mean autocorrelation function from the mean autocorrelation function.  The residuals obtained represent the oscillations within the autocorrelation function:
\begin{center}
\includegraphics[width=.9\linewidth]{residual_example.png}
\end{center}

This can be subject to further analysis.  Here, I estimated the amplitude of these oscillations based on the height of the peak in its Fourier transform (\(A = \sqrt{2y}\)), shown as red dotted lines.

This amplitude can be computed as the amplitude of noise varies, and I show that as the noise amplitude increases, the amplitude of the oscillations in the autocorrelation function decreases:
\begin{center}
\includegraphics[width=.9\linewidth]{birthrate_vs_acfamp.png}
\end{center}

To quantify the variation between autocorrelation functions between replicates, I computed the standard deviation autocorrelation function values at each lag and the area under this curve, as previously.  My calculations demonstrate that higher birthrate increases the variation between replicates:
\begin{center}
\includegraphics[width=.9\linewidth]{birthrate_vs_auc.png}
\end{center}

\item Conclusions
\label{sec:orge2a0d5d}

If a population of replicate oscillatory time series is modelled with the sum of sinusoids and Gillespie noise, then the birth rate and death rate can control the shape of the autocorrelation function.  The death rate controls the timescale of noise and thus how fast the autocorrelation decays as lag increases.  The birth rate controls the amplitude of noise and thus controls how robust the autocorrelation function is.  Knowing these relationships, one can deduce noise parameters from the autocorrelation functions of real signals.

Gillespie noise seems to model the noise I observe in experiments better than white noise, and I can even tune the parameters to create a better fit.
\end{enumerate}

\item Compare with biological oscillator
\label{sec:orgbccdb4a}

My intention is to have it model oscillations of flavin fluorescence that act as a proxy for the yeast metabolic cycle:

[FIGURE: some sample time series of sinusoids side-by-side with flavin oscillations]

\begin{center}
\includegraphics[width=.9\linewidth]{26643_ts.png}
\end{center}

\begin{center}
\includegraphics[width=.9\linewidth]{fy4_26643_plots_06.png}
\end{center}
\end{enumerate}

\item Autocorrelation on FitzHugh-Nagumo oscillator
\label{sec:org368123f}

\begin{enumerate}
\item Without noise
\label{sec:orgd112f31}

Generated 400 oscillators with \(RI_{ext}\) = 0.4, \(\tau\) = 12.5, \(a\) = 0.7, \(b\) = 0.82, all out of phase.  This is one of them:

\begin{center}
\includegraphics[width=.9\linewidth]{fitzhughnagumo_sample.png}
\end{center}

Autocorrelation function, lag axis scaled by period.  Note slightly different shape of oscillations here compared to sinusoid:

\begin{center}
\includegraphics[width=.9\linewidth]{fitzhughnagumo_acf_scalelag.png}
\end{center}

\item With Gaussian noise
\label{sec:orgaa2bb0c}

Sample time series:
\begin{center}
\includegraphics[width=.9\linewidth]{noisyfitzhughnagumo_sample.png}
\end{center}

ACF:
\begin{center}
\includegraphics[width=.9\linewidth]{noisyfitzhughnagumo_acf_scalelag.png}
\end{center}

\item With Gillespie noise
\label{sec:org3badb76}

\(k_{0} = 5, d_{0} = 0.05\)

Sample time series: \ldots{}

ACF: \ldots{}

\item Compare with biological oscillator
\label{sec:orga655348}

My intention is to have it model periodic changes in histone 2B intensity levels and yeast cells progress through the cell division cycle.

[FIGURE: some sample time series of FHNs side-by-side with histone 2B oscillations]

\begin{center}
\includegraphics[width=.9\linewidth]{htb2mCherry_26643_plots_purple_01.pdf}
\end{center}

\begin{center}
\includegraphics[width=.9\linewidth]{htb2mCherry_26643_plots_mCh_06.png}
\end{center}
\end{enumerate}
\end{enumerate}

% \subsection{Discussion}
% \label{sec:analysis-correlation-discussion}

My investigation aims to address a signal processing question.  Therefore, for the purposes of my investigation, it is not important that these oscillators function as an accurate model of the biological systems responsible for the biological oscillations observed.  Indeed, given that up to 50 flavoproteins may be responsible for flavin autofluorescence, a component of such a poorly biochemically characterised system like the yeast metabolic cycle, it is not feasible to find a mathematical model that accurately describes the biological oscillations.

So long as the time series resemble the real oscillators of interest, the hope is that the conclusions from investigating our simple \& well-characterised models may answer questions on the behaviour and relationships between our real oscillators. [this sentence is a bit vague, but will revisit this after I weave together the story]  Potentially, this investigation can be extended to oscillators modelled by other systems of differential equations that describe other biological rhythms.
